#!/usr/bin/env python3
"""
äº‘å°æ§åˆ¶å™¨æ¨¡å— - CameraController ç±»
å¤„ç† PTZ æ§åˆ¶å’Œæ™ºèƒ½æ‰«æé€»è¾‘
"""

import json
import subprocess
import threading
import time
import urllib.request
import urllib.parse
from typing import Optional, TYPE_CHECKING

from .config import (
    CAMERA_RTSP, CAPTURE_SEEK_TIME, CAPTURE_WIDTH, CAPTURE_HEIGHT, CAPTURE_QUALITY,
    DEVICE_SERIAL, ACCESS_TOKEN, ROTATION_SPEED,
    LEFT_LIMIT_STEP_DURATION, TURN_STABILIZE_TIME,
    CENTER_THRESHOLD, MAX_CENTER_ADJUST,
    DETECTION_SLEEP_TIME, TRACK_SCAN_DELAY,
    DIR_LEFT_CODE, DIR_RIGHT_CODE, DIR_UP_CODE, DIR_DOWN_CODE,
    PTZ_ERROR_CODES
)
from .stream import VideoStream
from .tracking import TrackingMemory

if TYPE_CHECKING:
    from .vision import VisionAnalyzer


class CameraController:
    """æ‘„åƒå¤´æ§åˆ¶å™¨ - æ”¯æŒå®æ—¶è§†é¢‘æµå’Œæ™ºèƒ½è¿½è¸ª"""

    def __init__(self):
        self.video_stream: Optional[VideoStream] = None
        self.stream_active = False
        self.tracking_memory = TrackingMemory()
        # å‚ç›´è¾¹ç•Œè®°å½•
        self.hit_up_limit = False
        self.hit_down_limit = False
        self._ptz_lock = threading.Lock()
        self.center_and_wait_mode = False

    def start_stream(self, use_gpu: bool = False, force_restart: bool = False) -> bool:
        """å¯åŠ¨å®æ—¶è§†é¢‘æµï¼ˆæ”¯æŒå¤ç”¨ï¼‰"""
        if self.stream_active and self.video_stream is not None and not force_restart:
            return True
        
        if force_restart and self.stream_active:
            self.stop_stream()

        self.video_stream = VideoStream(
            rtsp_url=CAMERA_RTSP,
            width=CAPTURE_WIDTH,
            height=CAPTURE_HEIGHT,
            buffer_size=3,
            use_gpu=use_gpu
        )

        if self.video_stream.start():
            self.stream_active = True
            time.sleep(0.5)
            return True
        return False
    
    def stop_stream(self, cleanup: bool = True):
        """åœæ­¢è§†é¢‘æµ"""
        if self.video_stream:
            self.video_stream.stop()
            if cleanup:
                self.video_stream = None
                self.stream_active = False
            else:
                self.stream_active = False

    def capture(self, output_path: str = "/tmp/mooer_view.jpg") -> str:
        """æŠ“å–å½“å‰ç”»é¢ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨è§†é¢‘æµ
        if self.stream_active and self.video_stream:
            frame = self.video_stream.get_frame()
            if frame is not None:
                import cv2
                cv2.imwrite(output_path, frame)
                return output_path
        
        # å›é€€åˆ° ffmpeg æˆªå›¾
        cmd = [
            "ffmpeg",
            "-rtsp_transport", "tcp",
            "-i", CAMERA_RTSP,
            "-ss", CAPTURE_SEEK_TIME,
            "-vframes", "1",
            "-vf", f"scale={CAPTURE_WIDTH}:{CAPTURE_HEIGHT}",
            "-q:v", str(CAPTURE_QUALITY),
            output_path,
            "-y",
        ]
        result = subprocess.run(cmd, capture_output=True)
        if result.returncode != 0:
            raise RuntimeError(f"æˆªå›¾å¤±è´¥: {result.stderr.decode()}")
        return output_path
    
    def get_frame(self) -> Optional:
        """è·å–å½“å‰å¸§"""
        if self.video_stream:
            return self.video_stream.get_frame()
        return None

    def ptz_turn(self, direction: str, duration: float) -> bool:
        """äº‘å°è½¬åŠ¨ï¼ˆæ°´å¹³æˆ–å‚ç›´ï¼Œé˜»å¡å¼ï¼‰"""
        direction_map = {
            "left": DIR_LEFT_CODE,
            "right": DIR_RIGHT_CODE,
            "up": DIR_UP_CODE,
            "down": DIR_DOWN_CODE,
        }

        if direction not in direction_map:
            print(f"âš ï¸  æœªçŸ¥æ–¹å‘: {direction}")
            return False

        dir_code = direction_map[direction]

        try:
            warning = self._ptz_control("start", dir_code)
            if warning:
                return False

            time.sleep(float(duration))
            self._ptz_control("stop", dir_code)
            return True
        except Exception as e:
            print(f"âš ï¸  PTZè½¬åŠ¨å¼‚å¸¸: {e}")
            return False

    def ptz_turn_async(self, direction: str):
        """å¼‚æ­¥å¯åŠ¨äº‘å°è½¬åŠ¨ï¼ˆéé˜»å¡ï¼‰"""
        direction_map = {
            "left": DIR_LEFT_CODE,
            "right": DIR_RIGHT_CODE,
            "up": DIR_UP_CODE,
            "down": DIR_DOWN_CODE,
        }

        if direction not in direction_map:
            print(f"âš ï¸  æœªçŸ¥æ–¹å‘: {direction}")
            return False, 0

        dir_code = direction_map[direction]
        warning = self._ptz_control("start", dir_code)
        if warning:
            return False, 0

        return True, dir_code

    def ptz_stop(self, direction: int) -> None:
        """åœæ­¢æŒ‡å®šæ–¹å‘çš„è½¬åŠ¨"""
        self._ptz_control("stop", direction)

    def center_person(self, offset_x: float, offset_y: float = 0) -> bool:
        """å°†äººç‰©ç§»åˆ°ç”»é¢ä¸­å¤®"""
        adjusted = False
        
        try:
            # æ°´å¹³è°ƒæ•´
            if abs(offset_x) >= CENTER_THRESHOLD:
                angle = offset_x * MAX_CENTER_ADJUST
                direction = "left" if offset_x < 0 else "right"
                duration = abs(angle) / ROTATION_SPEED
                try:
                    self.ptz_turn(direction, duration)
                    adjusted = True
                except Exception as e:
                    print(f"   âš ï¸ æ°´å¹³è°ƒæ•´å¤±è´¥: {e}")
            
            # å‚ç›´è°ƒæ•´
            VERTICAL_THRESHOLD = 0.3
            if abs(offset_y) >= VERTICAL_THRESHOLD:
                direction = "up" if offset_y < 0 else "down"
                
                if direction == "up" and self.hit_up_limit:
                    pass
                elif direction == "down" and self.hit_down_limit:
                    pass
                else:
                    tilt_duration = min(abs(offset_y) * 0.5, 0.3)
                    try:
                        success = self.ptz_turn(direction, tilt_duration)
                        if not success:
                            if direction == "up":
                                self.hit_up_limit = True
                            else:
                                self.hit_down_limit = True
                        else:
                            adjusted = True
                    except Exception as e:
                        print(f"   âš ï¸ å‚ç›´è°ƒæ•´å¤±è´¥: {e}")
            
            if adjusted:
                time.sleep(0.5)
        except Exception as e:
            print(f"âš ï¸  center_person å¼‚å¸¸: {e}")
        
        return adjusted

    def _ptz_control(self, action: str, direction: int) -> Optional[str]:
        """è°ƒç”¨è¤çŸ³äº‘ API"""
        with self._ptz_lock:
            data = urllib.parse.urlencode({
                "accessToken": ACCESS_TOKEN,
                "deviceSerial": DEVICE_SERIAL,
                "channelNo": 1,
                "direction": direction,
                "speed": 1,
            })

            url = f"https://open.ys7.com/api/lapp/device/ptz/{action}"
            req = urllib.request.Request(url, data=data.encode(), method="POST")

            try:
                with urllib.request.urlopen(req, timeout=10) as resp:
                    result = json.loads(resp.read().decode())
                    code = result.get("code")
                    msg = result.get("msg", "")

                    if code == "200":
                        return None

                    if code in PTZ_ERROR_CODES:
                        print(f"âš ï¸  PTZ [{code}] {PTZ_ERROR_CODES[code]}: {msg}")
                        if code == "20006" or "é™ä½" in msg:
                            return msg
                        return None
                    else:
                        print(f"âš ï¸  PTZ [{code}] {msg}")
                        if "é™ä½" in msg:
                            return msg
                        return None

            except Exception as e:
                print(f"âŒ PTZ å¼‚å¸¸: {e}")
                return str(e)

    def goto_left_limit(self, vision: "VisionAnalyzer" = None) -> bool:
        """è½¬åˆ°å·¦æé™ä½ç½®"""
        print("\nğŸ¯ è½¬åˆ°å·¦æé™...")
        print("-" * 50)

        left_steps = 0
        while True:
            success = self.ptz_turn("left", LEFT_LIMIT_STEP_DURATION)
            if not success:
                print(f"ğŸš§ åˆ°è¾¾å·¦æé™")
                break
            left_steps += 1

            if vision:
                time.sleep(DETECTION_SLEEP_TIME)
                try:
                    frame = self.get_frame()
                    if frame is not None:
                        has_person, _ = vision.check_person(frame=frame)
                        if has_person:
                            print("   æ£€æµ‹åˆ°äººç‰©ï¼åœæ­¢è½¬åŠ¨")
                            position = vision.analyze_position(frame=frame)
                            offset_x, offset_y = vision.get_person_offset(frame=frame)
                            self.center_person(offset_x, offset_y)
                            return True
                except Exception as e:
                    print(f"âš ï¸  æ£€æµ‹å¼‚å¸¸: {e}")

            time.sleep(DETECTION_SLEEP_TIME)

        print(f"âœ… å·¦æé™å®šä½å®Œæˆ (è½¬äº† {left_steps} æ­¥)")
        print("-" * 50)
        return False

    def human_steps(self, vision: "VisionAnalyzer", num_steps: int = 8, total_angle: float = 180) -> bool:
        """human å¤šæ­¥æ‰«æç­–ç•¥"""
        step_size = total_angle / num_steps
        step_duration = step_size / ROTATION_SPEED

        print(f"\nğŸ”„ å¯åŠ¨{num_steps}æ­¥æ‰«æ...")
        print("=" * 60)

        # é¢„æ£€æŸ¥
        frame = self.get_frame()
        if frame is not None and vision.check_person(frame=frame)[0]:
            print("å½“å‰ä½ç½®å·²æœ‰äººï¼")
            position = vision.analyze_position(frame=frame)
            print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
            return True

        # è½¬åˆ°å·¦æé™
        if self.goto_left_limit(vision=vision):
            return True

        # å¤šæ­¥æ‰«æ
        print(f"\nğŸ“ å¼€å§‹{num_steps}æ­¥æ‰«æ...")
        print("-" * 60)

        for i in range(num_steps):
            print(f"\nğŸ” æ­¥éª¤ {i + 1}/{num_steps}")

            if i > 0:
                print("   â†’ å³è½¬...", end=" ", flush=True)
                self.ptz_turn("right", step_duration)
                print("âœ…")
                time.sleep(TURN_STABILIZE_TIME)

            print("   ğŸ“¸ æ£€æµ‹äººç‰©...", end=" ", flush=True)
            frame = self.get_frame()
            if frame is not None and vision.check_person(frame=frame)[0]:
                print("ğŸ‘¤ æœ‰äººï¼")
                offset_x, offset_y = vision.get_person_offset(frame=frame)
                position = vision.analyze_position(offset_x=offset_x)
                print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
                
                if self.center_and_wait_mode:
                    print("   ğŸ¯ æ­£åœ¨æ‰§è¡Œäººç‰©å±…ä¸­...")
                    self.center_person(offset_x, offset_y)
                    time.sleep(2.0)
                
                return True

        print("\n" + "=" * 60)
        print(f"âš ï¸  {num_steps}æ­¥æ‰«ææœªå‘ç°äºº")
        return False

    def human_steps_fast(self, vision: "VisionAnalyzer", detect_interval: float = 0.1) -> bool:
        """å¿«é€Ÿæ‰«ææ‰¾äººï¼ˆå·¦æé™ â†’ å³æé™ï¼‰"""
        import time

        print(f"\nğŸš€ å¯åŠ¨å¿«é€Ÿæ‰«æ...")
        print("=" * 60)

        # é¢„æ£€æŸ¥
        frame = self.get_frame()
        if frame is not None and vision.check_person(frame=frame)[0]:
            print("âœ… å½“å‰ä½ç½®å·²æœ‰äººï¼")
            offset_x, offset_y = vision.get_person_offset(frame=frame)
            position = vision.analyze_position(offset_x=offset_x)
            print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
            self.center_person(offset_x, offset_y)
            return True

        # æ­¥è¿›å¼è½¬åˆ°å·¦æé™
        print("ğŸ¯ æ­¥è¿›è½¬åˆ°å·¦æé™...")
        step_duration = 0.15
        max_steps = 25
        left_steps = 0

        for i in range(max_steps):
            success = self.ptz_turn("left", step_duration)
            if not success:
                print(f"ğŸš§ åˆ°è¾¾å·¦æé™")
                break
            left_steps += 1

            if i % 2 == 0:
                try:
                    frame = self.get_frame()
                    if frame is not None and vision.check_person(frame=frame)[0]:
                        print(f"âœ… å·¦è½¬é€”ä¸­å‘ç°äººï¼")
                        offset_x, offset_y = vision.get_person_offset(frame=frame)
                        position = vision.analyze_position(offset_x=offset_x)
                        print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
                        self.center_person(offset_x, offset_y)
                        return True
                except Exception as e:
                    print(f"âš ï¸  æ£€æµ‹å¼‚å¸¸: {e}")

        print(f"âœ… å·¦æé™å®šä½å®Œæˆ")

        # æ­¥è¿›å¼å‘å³æ‰«æ
        print(f"\nğŸ“ å¼€å§‹å‘å³æ‰«æ...")
        print("-" * 40)

        right_steps = 0
        max_right_steps = 80

        for i in range(max_right_steps):
            success = self.ptz_turn("right", step_duration)
            if not success:
                print(f"ğŸš§ åˆ°è¾¾å³æé™ï¼Œæ‰«æå®Œæˆ")
                break

            right_steps += 1

            if i % 2 == 0:
                try:
                    frame = self.get_frame()
                    if frame is not None and vision.check_person(frame=frame)[0]:
                        current_angle = right_steps * step_duration * ROTATION_SPEED
                        print(f"\nâœ… å³è½¬é€”ä¸­å‘ç°äººï¼")
                        offset_x, offset_y = vision.get_person_offset(frame=frame)
                        position = vision.analyze_position(offset_x=offset_x)
                        print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
                        self.center_person(offset_x, offset_y)
                        return True
                except Exception as e:
                    print(f"âš ï¸  æ£€æµ‹å¼‚å¸¸: {e}")

        print(f"\nâš ï¸ æ°´å¹³æ‰«æå®Œæˆï¼Œæœªå‘ç°äºº")
        return False

    def human_steps_smart(self, vision: "VisionAnalyzer") -> bool:
        """æ™ºèƒ½æƒ¯æ€§æ‰«ææ‰¾äºº"""
        import time

        memory = self.tracking_memory
        step_duration = 0.15

        print(f"\nğŸ§  å¯åŠ¨æ™ºèƒ½æƒ¯æ€§æ‰«æ...")
        print("=" * 60)

        if memory.is_fresh() and memory.confidence > 0.3:
            print(f"ğŸ“ æœ‰æœ‰æ•ˆè®°å¿†: æœ€åè§’åº¦ {memory.last_angle:.0f}Â°")
            predicted_dir = memory.get_predicted_direction()

            if predicted_dir == "right":
                print(f"\nğŸ¯ ç­–ç•¥: äººå‘å³èµ°ï¼Œä¼˜å…ˆå‘å³æ‰«æ â†’")
                return self._scan_with_fallback(vision, "right", memory.last_angle)
            elif predicted_dir == "left":
                print(f"\nğŸ¯ ç­–ç•¥: äººå‘å·¦èµ°ï¼Œä¼˜å…ˆå‘å·¦æ‰«æ â†")
                return self._scan_with_fallback(vision, "left", memory.last_angle)

        print("ğŸ“­ æ— æœ‰æ•ˆè®°å¿†æˆ–è®°å¿†è¿‡æœŸ")
        print("ğŸ¯ ç­–ç•¥: å®Œæ•´æ‰«æ")
        return self.human_steps_fast(vision)

    def _scan_with_fallback(self, vision: "VisionAnalyzer", priority_dir: str, start_angle: float) -> bool:
        """ä¼˜å…ˆæ–¹å‘æ‰«æï¼Œæœªæ‰¾åˆ°åˆ™å›é€€åå‘æ‰«æ"""
        step_duration = 0.15
        max_steps = 40

        print(f"\nğŸ” ä¼˜å…ˆå‘{priority_dir}æ‰«æ...")
        print("-" * 40)

        for i in range(max_steps):
            success = self.ptz_turn(priority_dir, step_duration)
            if not success:
                break

            if i % 2 == 0:
                try:
                    frame = self.get_frame()
                    if frame is not None and vision.check_person(frame=frame)[0]:
                        print(f"\nâœ… {priority_dir}å‘æ‰«æå‘ç°äººï¼")
                        offset_x, offset_y = vision.get_person_offset(frame=frame)
                        position = vision.analyze_position(offset_x=offset_x)
                        print(f"   è¯­éŸ³æ’­æŠ¥: æ‰¾åˆ°ä½ äº†ï¼Œ{position}")
                        self.center_person(offset_x, offset_y)
                        return True
                except Exception as e:
                    print(f"âš ï¸  æ£€æµ‹å¼‚å¸¸: {e}")

        # æœªæ‰¾åˆ° -> å›é€€åå‘æ‰«æ
        opposite = "left" if priority_dir == "right" else "right"
        print(f"\nâ†©ï¸ ä¼˜å…ˆæ–¹å‘æœªæ‰¾åˆ°ï¼Œå›é€€å‘{opposite}æ‰«æ...")
        
        return False
