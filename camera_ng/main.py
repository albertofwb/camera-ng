#!/usr/bin/env python3
"""
Mooer Camera NG - ä¸»å…¥å£
é‡æ„åçš„æ¨¡å—åŒ–æ™ºèƒ½è§†è§’æ§åˆ¶ç³»ç»Ÿ
"""

import faulthandler
import fcntl
import os
import subprocess
import sys
import time
from collections import deque

# å¯ç”¨ faulthandlerï¼Œåœ¨å´©æºƒæ—¶æ‰“å° Python å †æ ˆ
faulthandler.enable()

from camera_ng import (
    DEFAULT_NUM_STEPS, DEFAULT_TOTAL_ANGLE,
    ROTATION_SPEED, TRACK_CHECK_INTERVAL, DETECTION_INTERVAL,
    TRACKER_MAX_AGE, TRACKER_MIN_HITS,
    CAPTURE_WIDTH, CAPTURE_HEIGHT, LOCK_FILE,
    CAMERA_RTSP, DEVICE_SERIAL, ACCESS_TOKEN,
    CameraController, VisionAnalyzer,
    PersonTracker, TrackingMemory
)


def validate_config():
    """éªŒè¯å¿…è¦é…ç½®æ˜¯å¦å­˜åœ¨"""
    errors = []
    
    if CAMERA_RTSP is None:
        errors.append("  - camera.rtsp_url: RTSP æµåœ°å€æœªé…ç½®")
    if DEVICE_SERIAL is None:
        errors.append("  - camera.device_serial: è®¾å¤‡åºåˆ—å·æœªé…ç½®")
    if ACCESS_TOKEN is None:
        errors.append("  - camera.access_token: è¤çŸ³äº‘ AccessToken æœªé…ç½®")
    
    if errors:
        print("\n" + "=" * 60)
        print("âŒ é…ç½®é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„æ•æ„Ÿä¿¡æ¯")
        print("=" * 60)
        print("\nè¯·åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€åˆ›å»º camera-config.yaml æ–‡ä»¶ï¼š")
        print("  1. ./memory/camera-config.yaml")
        print("  2. ~/.openclaw/workspace/memory/camera-config.yaml")
        print("  3. ~/clawd/memory/camera-config.yaml")
        print("  4. ~/.config/mooer-camera/config.yaml")
        print("\nç¼ºå¤±çš„é…ç½®é¡¹ï¼š")
        for err in errors:
            print(err)
        print("\ncamera-config.yaml ç¤ºä¾‹æ ¼å¼ï¼š")
        print("""
camera:
  rtsp_url: "rtsp://admin:PASSWORD@IP:554/h264/ch1/main/av_stream"
  device_serial: "YOUR_DEVICE_SERIAL"
  access_token: "YOUR_ACCESS_TOKEN"
  capture:
    seek_time: "00:00:00.5"
    resolution:
      width: 640
      height: 360
    quality: 2
  ptz:
    rotation_speed: 28
""")
        print("=" * 60)
        sys.exit(1)


# å¯åŠ¨æ—¶éªŒè¯é…ç½®
validate_config()


class SmartCamera:
    """æ™ºèƒ½æ‘„åƒå¤´ç³»ç»Ÿï¼ˆhuman ä¸“ç”¨ï¼‰"""

    def __init__(self):
        self.camera = CameraController()
        self.vision = VisionAnalyzer()

    def human(self, num_steps: int = DEFAULT_NUM_STEPS,
              total_angle: float = DEFAULT_TOTAL_ANGLE,
              use_gpu: bool = False, smart: bool = True,
              fast: bool = False, keep_stream: bool = True,
              center_and_wait: bool = False) -> bool:
        """æ‰§è¡Œ human æ‰«æï¼Œæ‰¾åˆ°äººè¿”å›True"""
        if not self.camera.stream_active:
            print("ğŸ¥ å¯åŠ¨è§†é¢‘æµ...")
            if not self.camera.start_stream(use_gpu=use_gpu):
                print("âŒ æ— æ³•å¯åŠ¨è§†é¢‘æµ")
                return False
            time.sleep(0.5)
        else:
            print("ğŸ”„ å¤ç”¨å·²æœ‰è§†é¢‘æµ...")

        try:
            self.camera.center_and_wait_mode = center_and_wait
            
            if smart:
                result = self.camera.human_steps_smart(self.vision)
            elif fast:
                result = self.camera.human_steps_fast(self.vision)
            else:
                result = self.camera.human_steps(
                    self.vision, num_steps=num_steps, total_angle=total_angle
                )
        finally:
            if not keep_stream:
                self.camera.stop_stream()

        return result
    
    def stop(self):
        """å®Œå…¨åœæ­¢å¹¶æ¸…ç†èµ„æº"""
        self.camera.stop_stream()
        print("âœ… æ™ºèƒ½æ‘„åƒå¤´ç³»ç»Ÿå·²åœæ­¢")
    
    def human_smart_only(self) -> bool:
        """æ™ºèƒ½æ‰«æï¼ˆå¤ç”¨å·²æœ‰æµï¼‰"""
        return self.human(smart=True)


class SingleInstanceLock:
    """å•å®ä¾‹æ–‡ä»¶é”"""

    def __init__(self, lock_file: str = LOCK_FILE):
        self.lock_file = lock_file
        self.fd = None

    def acquire(self) -> bool:
        """è·å–æ–‡ä»¶é”"""
        try:
            self.fd = open(self.lock_file, "w")
            fcntl.flock(self.fd.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
            self.fd.write(str(os.getpid()))
            self.fd.flush()
            return True
        except (IOError, OSError):
            if self.fd:
                self.fd.close()
                self.fd = None
            return False

    def release(self):
        """é‡Šæ”¾æ–‡ä»¶é”"""
        if self.fd:
            try:
                fcntl.flock(self.fd.fileno(), fcntl.LOCK_UN)
                self.fd.close()
                if os.path.exists(self.lock_file):
                    os.remove(self.lock_file)
            except (IOError, OSError):
                pass
            finally:
                self.fd = None

    def __enter__(self):
        if not self.acquire():
            raise RuntimeError("å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿è¡Œ")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()


def check_single_instance():
    """æ£€æŸ¥æ˜¯å¦å•å®ä¾‹è¿è¡Œ"""
    lock = SingleInstanceLock()
    if not lock.acquire():
        print("âŒ é”™è¯¯ï¼šå¦ä¸€ä¸ª mooer_camera å®ä¾‹æ­£åœ¨è¿è¡Œ")
        print(f"   é”æ–‡ä»¶: {LOCK_FILE}")
        print("   è¯·å…ˆåœæ­¢å…¶ä»–å®ä¾‹å†è¿è¡Œ")
        sys.exit(1)
    return lock


def track_human_realtime(num_steps: int = DEFAULT_NUM_STEPS,
                         total_angle: float = 360,
                         detection_interval: int = DETECTION_INTERVAL,
                         use_gpu: bool = False) -> None:
    """å®æ—¶ç›®æ ‡è·Ÿè¸ªæ¨¡å¼"""
    cam = SmartCamera()
    tracker = PersonTracker(
        yolo_model="yolov8n",
        confidence=0.5,
        detection_interval=detection_interval
    )
    
    cycle_count = 0
    person_found = False
    analyzing = False
    lost_count = 0
    LOST_THRESHOLD = 5
    
    fps_history = deque(maxlen=30)
    last_time = time.time()

    print("\n" + "=" * 60)
    print("ğŸ” å¯åŠ¨å®æ—¶ç›®æ ‡è·Ÿè¸ªæ¨¡å¼ (Real-time + SORT)")
    print("=" * 60)
    print(f"é…ç½®: {num_steps}æ­¥/{total_angle}Â°")
    print(f"YOLOæ£€æµ‹é—´éš”: æ¯{detection_interval}å¸§")
    print(f"è·Ÿè¸ªå™¨: SORT (max_age={TRACKER_MAX_AGE}, min_hits={TRACKER_MIN_HITS})")
    print(f"è§†é¢‘è§£ç : {'GPU (CUDA)' if use_gpu else 'CPU'}")
    print("æŒ‰ Ctrl+C åœæ­¢è¿½è¸ª")
    print("=" * 60 + "\n")

    if not cam.camera.start_stream(use_gpu=use_gpu):
        print("âŒ æ— æ³•å¯åŠ¨è§†é¢‘æµ")
        return

    try:
        while True:
            cycle_count += 1
            current_time = time.time()
            
            fps_history.append(1.0 / (current_time - last_time + 0.001))
            avg_fps = sum(fps_history) / len(fps_history)
            last_time = current_time

            if not person_found:
                print(f"\n{'=' * 60}")
                print(f"ğŸ”„ ç¬¬ {cycle_count} è½® | æ‰§è¡Œæ™ºèƒ½æ‰«æ...")
                print(f"{'=' * 60}")

                person_found = cam.human_smart_only()

                if person_found:
                    print("âœ… æ‰¾åˆ°ç›®æ ‡ï¼")
                    cam.camera.tracking_memory.reset()
                    
                    if not cam.camera.stream_active:
                        if not cam.camera.start_stream():
                            return
                        time.sleep(0.5)

                    init_attempts = 0
                    max_init_attempts = 10
                    
                    while init_attempts < max_init_attempts:
                        frame = cam.camera.get_frame()
                        if frame is not None:
                            tracks = tracker.update(frame, force_detect=True)
                            if tracks:
                                analyzing = True
                                lost_count = 0
                                break
                        init_attempts += 1
                        time.sleep(0.1)
                    else:
                        person_found = False
                        continue

                    analyzing = True
                    lost_count = 0
                else:
                    print("æœªæ‰¾åˆ°ï¼Œç»§ç»­æ‰«æ...")
                    if not cam.camera.start_stream():
                        cam.camera.start_stream()
                    time.sleep(0.5)
                    
            elif analyzing:
                frame = cam.camera.get_frame()
                if frame is None:
                    time.sleep(0.01)
                    continue
                
                tracks = tracker.update(frame)
                main_person = tracker.get_main_person()
                
                detect_mode = "DETECT" if cycle_count % detection_interval == 0 else "TRACK "
                status = f"\rğŸ“Š [{detect_mode}] FPS:{avg_fps:.1f} | Tracks:{len(tracks)}"
                if main_person:
                    cx, cy = main_person.bbox[[0, 2]].mean(), main_person.bbox[[1, 3]].mean()
                    offset_x = (cx - CAPTURE_WIDTH/2) / (CAPTURE_WIDTH/2)
                    status += f" | MainID:{main_person.id} offset:{offset_x:+.2f}"
                print(status, end="", flush=True)
                
                if main_person:
                    cx = (main_person.bbox[0] + main_person.bbox[2]) / 2
                    cy = (main_person.bbox[1] + main_person.bbox[3]) / 2
                    offset_x = (cx - CAPTURE_WIDTH/2) / (CAPTURE_WIDTH/2)
                    offset_y = (cy - CAPTURE_HEIGHT/2) / (CAPTURE_HEIGHT/2)
                    
                    current_angle = cam.camera.tracking_memory.last_angle
                    if offset_x < -0.3:
                        current_angle = (current_angle - 20) % 360
                    elif offset_x > 0.3:
                        current_angle = (current_angle + 20) % 360
                    cam.camera.tracking_memory.update(current_angle)
                    
                    if abs(offset_x) > 0.5 or abs(offset_y) > 0.6:
                        print(f"\n   è°ƒæ•´: æ°´å¹³{offset_x:+.2f}, å‚ç›´{offset_y:+.2f}")
                        cam.camera.center_person(offset_x, offset_y)
                        time.sleep(0.8)
                    
                    lost_count = 0
                else:
                    lost_count += 1
                    if lost_count >= LOST_THRESHOLD:
                        print(f"\n   ä¸¢å¤±ç›®æ ‡ï¼Œé‡æ–°æ‰«æ...")
                        analyzing = False
                        person_found = False
                
                time.sleep(0.01)
            else:
                frame = cam.camera.get_frame()
                if frame is not None:
                    tracks = tracker.update(frame)
                    if tracks:
                        lost_count = 0
                    else:
                        lost_count += 1
                        if lost_count >= LOST_THRESHOLD:
                            person_found = False
                time.sleep(TRACK_CHECK_INTERVAL)

    except KeyboardInterrupt:
        print("\n\nåœæ­¢è¿½è¸ª...")
    finally:
        cam.camera.stop_stream()
        print("\nè¿½è¸ªå·²åœæ­¢")
        print(f"   å…±æ‰§è¡Œ {cycle_count} è½®")


def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("Mooer Camera NG - æ™ºèƒ½è§†è§’æ§åˆ¶ç³»ç»Ÿ")
    print("\nç”¨æ³•: python3 -m camera_ng <å‘½ä»¤> [é€‰é¡¹] [æ­¥æ•°] [è§’åº¦]")
    print("\nå¯ç”¨å‘½ä»¤:")
    print("  human [é€‰é¡¹] [æ­¥æ•°] [è§’åº¦]  - å¤šæ­¥æ‰«ææ‰¾äºº")
    print("  track [é€‰é¡¹] [æ­¥æ•°] [è§’åº¦]  - å®æ—¶è·Ÿè¸ªæ¨¡å¼")
    print("  shot [æ­¥æ•°] [è§’åº¦]          - æ‹ç…§å¹¶å‘é€")
    print("  calibrate                   - æ ¡å‡†äº‘å°è½¬é€Ÿ")
    print("\né€‰é¡¹:")
    print("  -h, --help                  - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
    print("  -g, --gpu                   - ä½¿ç”¨ GPU ç¡¬è§£")
    print("  --speed <åº¦/ç§’>             - æŒ‡å®šè½¬é€Ÿ")
    print("\nç¤ºä¾‹:")
    print("  python3 -m camera_ng human          # é»˜è®¤æ‰«æ")
    print("  python3 -m camera_ng track -g       # GPU å®æ—¶è·Ÿè¸ª")
    print("  python3 -m camera_ng shot 8 180     # æ‹ç…§æ¨¡å¼")


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    if len(sys.argv) < 2 or sys.argv[1] in ('-h', '--help'):
        show_help()
        sys.exit(0 if sys.argv[1] in ('-h', '--help') else 1)

    cmd = sys.argv[1]
    args = sys.argv[2:]

    # è§£æ GPU é€‰é¡¹
    use_gpu = False
    if "-g" in args or "--gpu" in args:
        use_gpu = True
        args = [a for a in args if a not in ["-g", "--gpu"]]

    # è§£æè½¬é€Ÿé€‰é¡¹
    global ROTATION_SPEED
    if "--speed" in args:
        speed_idx = args.index("--speed")
        if speed_idx + 1 < len(args):
            ROTATION_SPEED = float(args[speed_idx + 1])
            print(f"âš™ï¸  ä½¿ç”¨æŒ‡å®šè½¬é€Ÿ: {ROTATION_SPEED}Â°/s")
            args = args[:speed_idx] + args[speed_idx + 2:]

    num_steps = int(args[0]) if len(args) > 0 else DEFAULT_NUM_STEPS
    total_angle = float(args[1]) if len(args) > 1 else DEFAULT_TOTAL_ANGLE

    lock = check_single_instance()

    cam = None
    try:
        if cmd == "human":
            cam = SmartCamera()
            result = cam.human(num_steps=num_steps, total_angle=total_angle, use_gpu=use_gpu)
            print(f"\n{'='*60}")
            print(f"æ‰«æç»“æœ: {'æ‰¾åˆ°äºº' if result else 'æœªæ‰¾åˆ°äºº'}")
            print(f"{'='*60}")
            cam.stop()
            
        elif cmd == "shot":
            cam = SmartCamera()
            result = cam.human(num_steps=num_steps, total_angle=total_angle, 
                             use_gpu=use_gpu, center_and_wait=True)
            if result:
                img_path = cam.camera.capture()
                print(f"ğŸ“¸ å·²è‡ªåŠ¨æŠ“æ‹å¹¶å±…ä¸­: {img_path}")
                
                try:
                    target = "1115213761"
                    msg = "Albertï¼Œæˆ‘æŠ“æ‹åˆ°ä½ å•¦ï¼ğŸ“¸ğŸ’•"
                    send_cmd = [
                        "openclaw", "message", "send",
                        "--channel", "telegram",
                        "--target", target,
                        "--media", img_path,
                        "--message", msg
                    ]
                    print(f"ğŸ“¤ æ­£åœ¨é€šè¿‡ OpenClaw å‘é€ç…§ç‰‡...")
                    subprocess.run(send_cmd, check=True)
                    print("âœ… ç…§ç‰‡å‘é€æˆåŠŸï¼")
                except Exception as e:
                    print(f"âŒ ç…§ç‰‡å‘é€å¤±è´¥: {e}")
                    
            print(f"\n{'='*60}")
            print(f"æ‹ç…§ç»“æœ: {'æˆåŠŸ' if result else 'æœªæ‰¾åˆ°äºº'}")
            print(f"{'='*60}")
            cam.stop()
            
        elif cmd == "track":
            track_human_realtime(num_steps=num_steps, total_angle=total_angle, use_gpu=use_gpu)
            
        elif cmd == "calibrate":
            subprocess.run(["python3", "/home/albert/clawd/scripts/calibrate_speed.py"])
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {cmd}")
            print("æ”¯æŒå‘½ä»¤: human, shot, track, calibrate")
            sys.exit(1)
    finally:
        lock.release()


if __name__ == "__main__":
    main()
